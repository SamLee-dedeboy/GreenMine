{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "api_key = open(\"api_key\").readline()\n",
    "client = OpenAI(api_key=api_key)\n",
    "import json\n",
    "import requests\n",
    "import tiktoken\n",
    "def save_json(data, filepath=r'new_data.json'):\n",
    "    with open(filepath, 'w', encoding='utf-8') as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "\n",
    "def request_gpt4(messages, response_format=None):\n",
    "    if response_format == \"json\":\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            messages=messages,\n",
    "            response_format={ \"type\": \"json_object\" },\n",
    "        )\n",
    "    else:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            messages=messages,\n",
    "        )\n",
    "    return response.choices[0].message.content\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "    while len(enc.encode(text)) > 8191:\n",
    "        text = text[:-100]\n",
    "    url = 'https://api.openai.com/v1/embeddings'\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': \"Bearer {}\".format(api_key)\n",
    "    }\n",
    "    data = {\n",
    "        \"input\": text,\n",
    "        \"model\": model\n",
    "    }\n",
    "    res = requests.post(url, headers=headers, json=data)\n",
    "    res = res.json()\n",
    "    return res['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emotions)\n",
    "print(\"Happiness\".lower() in emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotion_definitions = open(\"emotion_definitions.txt\").readlines()\n",
    "emotions = list(map(lambda x: x.lower(), [\"Happiness\", \"Sadness\", \"Fear\", \"Disgust\", \"Anger\", \"Surprise\", \"Neutral\"]))\n",
    "\n",
    "def emotion_analysis(text):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a emotion analysis system. \n",
    "            You are given a conversation between two people: Interviewer and Interviewee. \n",
    "            You are asked to analyze the emotion of the interviewee. \n",
    "            Reply with exactly only one of the following emotions: Happiness, Sadness, Fear, Disgust, Anger, Surprise, Neutral.\n",
    "        \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": text\n",
    "        }\n",
    "    ]\n",
    "    emotion = request_gpt4(messages)\n",
    "    while emotion.lower() not in emotions:\n",
    "        emotion = request_gpt4(messages)\n",
    "        print(emotion)\n",
    "    return emotion\n",
    "\n",
    "def conversation_to_string(conversation):\n",
    "    res = \"\"\n",
    "    for content in conversation:\n",
    "        if content['speaker'] == '1':\n",
    "            res += \"Interviewer: \"\n",
    "        else:\n",
    "            res += \"Interviewee: \"\n",
    "        res += content['content'] + \"\\n\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "interview_data_files = glob.glob('../data/result/chunk_summaries/*.json')\n",
    "for interview_data_file in interview_data_files:\n",
    "    interview_data = json.load(open(interview_data_file))\n",
    "    print(interview_data_file)\n",
    "    for chunk in interview_data:\n",
    "        if \"emotion\" in chunk: continue\n",
    "        conversation = chunk['conversation']\n",
    "        conversation_str = conversation_to_string(conversation)\n",
    "        chunk['emotion'] = emotion_analysis(conversation_str)\n",
    "        print(chunk['emotion'])\n",
    "        print(conversation)\n",
    "        print(\"=====================================\")\n",
    "    save_json(interview_data, interview_data_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lyudao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
