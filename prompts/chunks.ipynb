{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "from pprint import pprint\n",
    "import requests\n",
    "api_key = open(\"api_key\").read()\n",
    "openai.api_key = api_key\n",
    "\n",
    "def save_json(data, filepath=r'new_data.json'):\n",
    "    with open(filepath, 'w', encoding='utf-8') as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "\n",
    "def request_chatgpt_gpt4(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k-0613\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   # text = text.replace(\"\\n\", \" \")\n",
    "   # return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "   url = 'https://api.openai.com/v1/embeddings'\n",
    "   headers = {\n",
    "      'Content-Type': 'application/json',\n",
    "      'Authorization': \"Bearer {}\".format(api_key)\n",
    "   }\n",
    "   data = {\n",
    "      \"input\": text,\n",
    "      \"model\": model\n",
    "   }\n",
    "   res = requests.post(url, headers=headers, json=data)\n",
    "   res = res.json()\n",
    "   return res['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying the traditional way: tokenize -> stop word removal -> word count\n",
    "# conclusion: does not work well\n",
    "import jieba\n",
    "import chinese_converter\n",
    "from collections import defaultdict\n",
    "# read stopwords from stopwords-master/all.txt\n",
    "stopwords = open('stopwords-master/all.txt', 'r', encoding='utf-8').read().split('\\n')\n",
    "stopwords+= ['说', '做', '讲', '东西', '真的', '事情', '是因为', '这件', '…']\n",
    "def clean(messages):\n",
    "    res = []\n",
    "    for message in messages:\n",
    "        simp_message = chinese_converter.to_simplified(message)\n",
    "        tokens = [token for token in jieba.cut(simp_message, cut_all=False) if token not in stopwords]\n",
    "        res.append(tokens)\n",
    "    return res\n",
    "def freq(tokens_list):\n",
    "    freq_dict = defaultdict(int)\n",
    "    for tokens in tokens_list:\n",
    "        for token in tokens:\n",
    "            freq_dict[token] += 1\n",
    "    freq_dict = {k: v for k, v in sorted(freq_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return freq_dict\n",
    "tokens_list = clean(interviewee_messages)\n",
    "for message in tokens_list:\n",
    "    freq_dict = freq([message])\n",
    "    print(freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final script: 1-3\n",
    "# 1. transform transcript to qa pairs\n",
    "def collect_interviewee_messages(transcripts):\n",
    "    # 0: interviewee, 1: interviewer\n",
    "    speakers = [0 if t['speaker'] == participant_id else 1 for t in transcripts]\n",
    "    qa_pairs = []\n",
    "    i = 0\n",
    "    cur_q = []\n",
    "    while i < len(speakers):\n",
    "        if i == 0:\n",
    "            cur_q.append(i)\n",
    "            i += 1\n",
    "            continue\n",
    "        if speakers[i] == 1: # interviewer\n",
    "            qa_pairs.append(cur_q)\n",
    "            cur_q = [i]\n",
    "            i += 1\n",
    "        else: # interviewee\n",
    "            cur_q.append(i)\n",
    "            i += 1\n",
    "    qa_pairs.append(cur_q)\n",
    "    return qa_pairs\n",
    "def qa_index_to_message(qa_pairs, transcripts):\n",
    "    res = []\n",
    "    for qa in qa_pairs:\n",
    "        res.append([transcripts[i]['content'] for i in qa])\n",
    "    return res\n",
    "\n",
    "participant_id = 'N6'\n",
    "section = \"topics\"\n",
    "for i in range(1, 20):\n",
    "    participant_id = 'N{}'.format(i)\n",
    "    # transcripts = json.load(open('../data/raw/transcript/json/{}_done.json'.format(participant_id)))\n",
    "    transcripts = json.load(open('../data/result/transcripts/{}_{}.json'.format(participant_id, section)))\n",
    "    interviewee_messages = [t['content'] for t in transcripts if t['speaker'] == participant_id]\n",
    "    interviewer_messages = [t['content'] for t in transcripts if t['speaker'] == '採訪者']\n",
    "    qa_pairs = collect_interviewee_messages(transcripts)\n",
    "    qa_messages = qa_index_to_message(qa_pairs, transcripts)\n",
    "    save_json(qa_messages, '../data/result/tmp/v3_1029/qa_messages_{}_{}.json'.format(participant_id, section))\n",
    "# print(len(qa_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. classify interviewer messages with chatgpt\n",
    "def classify_interviewer_message(question, answer):\n",
    "    message = [\n",
    "        # {\n",
    "        #     'role': 'system',\n",
    "        #     'content': \"\"\"\n",
    "        #         The user is dealing with a transcript of an interview.\n",
    "        #         In the transcript, some interviewer messages are just repeating what the interviewee said, these messages are less interesting.\n",
    "        #         Others are for invoking a new discussion, or asking about a new topic in the interview.\n",
    "        #         You are a classification system that helps user decide if a sentence is invoking a new topic.\n",
    "        #         Normally, if the sentence is long it should be yes.\n",
    "        #         Reply with \"yes\" if the sentence is worth further examination, otherwise reply with \"no\".\n",
    "        #     \"\"\"\n",
    "        # },\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': \"\"\"\n",
    "                你是一個訪談紀錄的分類系統。現在有一個很長的訪談紀錄，需要你幫忙分類。\n",
    "                用戶的需求是：在訪談紀錄中，有些發言是引導新的討論，有些發言只是重複之前的討論。\n",
    "                通常，如果發言很長或是有提到具體的名詞，就是引導新的討論, 請回答「是」。\n",
    "                如果發言很短且只是語助詞，比如‘真的喔？’，‘的確’， ‘有趣’，就不太可能是在引導新的討論，請回答「否」。\n",
    "                請判斷一個發言是否在引導新的討論，用「是」或「否」來回答。\n",
    "            \"\"\"\n",
    "        },\n",
    "        # example 1\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'name': 'example_user',\n",
    "            'content': '問：這麼多喔。'\n",
    "\n",
    "        },\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'name': 'example_system',\n",
    "            'content': '否'\n",
    "        },\n",
    "        # example 2\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'name': 'example_user',\n",
    "            'content': \"\"\"\n",
    "            問：的確，我們這邊就是社會，目前也還沒有說真的要針對哪一塊，但是我們是想要聊解現在這個狀況，就是綠島人民來說就是居民來說不就新居民就居民，他們現在重視有什麼樣的議題。\\n\n",
    "            \"\"\"\n",
    "\n",
    "        },\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'name': 'example_system',\n",
    "            'content': '是'\n",
    "        },\n",
    "        # example 3\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'name': 'example_user',\n",
    "            'content': \"\"\"\n",
    "            問：那您就是您覺得您在就是綠島工作，有沒有因為是綠島的緣故，就是讓您工作比較有挑戰性的地方？或者是有，就是特別特別喜歡的地方?\\n\n",
    "            \"\"\"\n",
    "\n",
    "        },\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'name': 'example_system',\n",
    "            'content': '是'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': \"問：{}\".format(question)\n",
    "        }\n",
    "    ]\n",
    "    response = request_chatgpt_gpt4(message)\n",
    "    return response\n",
    "\n",
    "section = \"topics\"\n",
    "for i in range(1, 20):\n",
    "    participant_id = 'N{}'.format(i)\n",
    "    # transcripts = json.load(open('../data/raw/transcript/json/{}_done.json'.format(participant_id)))\n",
    "    # transcripts = json.load(open('../data/result/transcripts/{}_{}.json'.format(participant_id, section)))\n",
    "    qa_pairs = json.load(open('../data/result/tmp/v3_1029/qa_messages_{}_{}.json'.format(participant_id, section)))\n",
    "    # interviewee_messages = [t['content'] for t in transcripts if t['speaker'] == participant_id]\n",
    "    # interviewer_messages = [t['content'] for t in transcripts if t['speaker'] == '採訪者']\n",
    "    res = []\n",
    "    print(\"participant_id: {}\".format(participant_id))\n",
    "    for qa_index, qa_pair in enumerate(qa_pairs):\n",
    "        if len(qa_pair) == 1:\n",
    "            qa_pair = ['（訪談開始）', qa_pair[0]]\n",
    "            qa_pairs[qa_index] = qa_pair\n",
    "        if len(qa_pair[0]) < 50 and qa_index > 0 and len(qa_pairs[qa_index-1][1]) < 30:\n",
    "            label = '否'\n",
    "        else:\n",
    "            label = classify_interviewer_message(qa_pair[0], qa_pair[1])\n",
    "            if label not in ['是', '否']:\n",
    "                label = classify_interviewer_message(qa_pair[0], qa_pair[1])\n",
    "                if label not in ['是', '否']:\n",
    "                    label = '否'\n",
    "        print(label, len(qa_pair[0]), len(qa_pairs[max(0, qa_index-1)][1]),qa_pair)\n",
    "        res.append({\n",
    "            'sentence': qa_pair[0],\n",
    "            'label': label\n",
    "        })\n",
    "    print(\"===========================\")\n",
    "    save_json(res, '../data/result/tmp/v3_1029/interviewer_message_classification_{}_{}.json'.format(participant_id, section))\n",
    "    # break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. chunk qa messages by topic \n",
    "def chunk_by_topic(qa_messages, speakers, interviewer_clf):\n",
    "    index = 0\n",
    "    interviewer_index = 0\n",
    "    chunks = []\n",
    "    new_chunk = []\n",
    "    for qa_index, qa in enumerate(qa_messages):\n",
    "        for message in qa:\n",
    "            if speakers[index] == 1:\n",
    "                new_chunk.append({\n",
    "                    \"speaker\": 1,\n",
    "                    \"content\": message\n",
    "                })\n",
    "                interviewer_index += 1\n",
    "            else:\n",
    "                new_chunk.append({\n",
    "                    \"speaker\": 0,\n",
    "                    \"content\": message\n",
    "                })\n",
    "            if qa_index < len(qa_messages)-1 and speakers[index+1] == 1 and interviewer_clf[interviewer_index] == 1:\n",
    "                chunks.append(new_chunk)\n",
    "                new_chunk = []\n",
    "            index += 1\n",
    "    chunks.append(new_chunk)\n",
    "    return chunks\n",
    "section = 'topics'\n",
    "for i in range(1, 20):\n",
    "    participant_id = 'N{}'.format(i)\n",
    "    # transcripts = json.load(open('../data/raw/transcript/json/{}_done.json'.format(participant_id)))\n",
    "    transcripts = json.load(open('../data/result/transcripts/{}_{}.json'.format(participant_id, section)))\n",
    "    res = []\n",
    "    print(\"participant_id: {}\".format(participant_id))\n",
    "    qa_messages = json.load(open('../data/result/tmp/v3_1029//qa_messages_{}_{}.json'.format(participant_id, section)))\n",
    "    speakers = [0 if t['speaker'] == participant_id else 1 for t in transcripts]\n",
    "    intvwer_clf = json.load(open('../data/result/tmp/v3_1029/interviewer_message_classification_{}_{}.json'.format(participant_id, section)))\n",
    "    intvwer_clf = [1 if i['label'] == '是' else 0 for i in intvwer_clf]\n",
    "    chunks = chunk_by_topic(qa_messages, speakers, intvwer_clf) \n",
    "    save_json(chunks, '../data/result/chunks/v2_1029/chunks_{}_{}.json'.format(participant_id, section))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate embeddings for each chunk\n",
    "section = 'topics'\n",
    "for i in range(1, 20):\n",
    "    participant_id = 'N{}'.format(i)\n",
    "    chunks = json.load(open('../data/result/chunks/v2_1029/chunks_{}_{}.json'.format(participant_id, section)))\n",
    "    for chunk_index, chunk in enumerate(chunks):\n",
    "        for message_index, message in enumerate(chunk):\n",
    "            message['chunk_index'] = chunk_index\n",
    "            message['message_index'] = message_index\n",
    "            try:\n",
    "                message['embedding'] = get_embedding(message['content'])\n",
    "            except:\n",
    "                print(participant_id, chunk_index, message_index)\n",
    "    save_json(chunks, '../data/result/chunk_embeddings/1029/chunks_{}_{}_with_embedding.json'.format(participant_id, section))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings (dep)\n",
    "embeddings = []\n",
    "for index, message in enumerate(interviewee_messages):\n",
    "    print('{}/{}'.format(index, len(interviewee_messages)))\n",
    "    embedding = get_embedding(message)\n",
    "    embeddings.append({\n",
    "        'content': message,\n",
    "        'embedding': embedding\n",
    "    })\n",
    "save_json(embeddings, '../data/result/interviewee_embeddings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sim matrix (dep)\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embeddings = json.load(open('../data/result/interviewee_embeddings.json'))\n",
    "vecs = [e['embedding'] for e in embeddings]\n",
    "sim_matrix = cosine_similarity(np.array(vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_by_embedding(sim_matrix):\n",
    "    chunks = []\n",
    "    length = sim_matrix.shape[0]\n",
    "    i = 0\n",
    "    while i < length:\n",
    "        prev_sim = 1\n",
    "        for j in range(i+1, length):\n",
    "            if j == i+1:\n",
    "                if sim_matrix[i][j] > 0.85:\n",
    "                    prev_sim = sim_matrix[i][j]\n",
    "                    chunks.append((i, j, prev_sim))\n",
    "                    continue\n",
    "                else:\n",
    "                    chunks.append((i, i, 1))\n",
    "                    i = i+1\n",
    "                    break\n",
    "            if sim_matrix[i][j] < 0.85 or prev_sim - sim_matrix[i][j] > 0.04:\n",
    "                i = j\n",
    "                break\n",
    "            else:\n",
    "                prev_sim = sim_matrix[i][j]\n",
    "                chunks.append((i, j, prev_sim))\n",
    "        if j == length-1:\n",
    "            i = length\n",
    "            break\n",
    "    return chunks\n",
    "chunks = chunk_by_embedding(sim_matrix)\n",
    "pprint(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_chunks(chunks_index, interviewee_messages):\n",
    "    chunks = defaultdict(list)\n",
    "    for i, j, _ in chunks_index:\n",
    "        if chunks[i] == []:\n",
    "            chunks[i].append(interviewee_messages[i])\n",
    "        if i == j: continue\n",
    "        chunks[i].append(interviewee_messages[j])\n",
    "    return list(chunks.values())\n",
    "message_chunks = collect_chunks(chunks, interviewee_messages)\n",
    "pprint(message_chunks[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sim matrix distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(data):\n",
    "    x_values = list(range(1, len(data) + 1))\n",
    "\n",
    "    # Create a line chart\n",
    "    plt.plot(x_values, data, marker='o', linestyle='-')\n",
    "    plt.title('Line Chart of similarity')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Value')\n",
    "    # Display the chart (if you're using a Jupyter Notebook, you can omit this line)\n",
    "    plt.show()\n",
    "def exclude(data, index):\n",
    "    return list(data)[:index] + list(data)[index+1:]\n",
    "plot(exclude(sim_matrix[2], 2))\n",
    "plot(exclude(sim_matrix[3], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_chunks = json.load(open('../data/result/chunks_N1.json'))\n",
    "print(len(interviewee_messages), len(response_chunks))\n",
    "summaries = []\n",
    "for chunk in response_chunks:\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': \"\"\"\n",
    "                You are a reporter in Taiwan. \n",
    "                You interviewed a person who is a local residence in Lyudao (綠島), a small island near Taiwan. \n",
    "                Please summarize the interview. Reply in traditional Chinese.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Interview: \\n' + \"\\n\".join(chunk)\n",
    "        }\n",
    "    ]\n",
    "    res = request_chatgpt_gpt4(messages)\n",
    "    summaries.append(res)\n",
    "    print(res)\n",
    "    print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(summaries, '../data/result/chunk_summaries.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lyudao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
