{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "from GPTUtils import query, prompts\n",
    "from openai import OpenAI\n",
    "def save_json(data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "# openai (temp)\n",
    "openai_api_key = open(\"openai_api_key\").read()\n",
    "openai_client=OpenAI(api_key=openai_api_key, timeout=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def identify_var_types(all_chunks, openai_client, system_prompt_blocks, user_prompt_blocks, prompt_variables):\n",
    "#     identify_var_type_prompt_list = []\n",
    "#     response_format, extract_response_func = None, None\n",
    "#     for chunk in all_chunks:\n",
    "#         conversation = chunk['conversation']\n",
    "#         prompt_variables['conversation'] = conversation_to_string(conversation)\n",
    "#         identify_var_type_prompt, response_format, extract_response_func = prompts.identify_var_type_prompt_factory(system_prompt_blocks, user_prompt_blocks, prompt_variables)\n",
    "#         identify_var_type_prompt_list.append(identify_var_type_prompt)\n",
    "#     identified_var_types = query.multithread_prompts(openai_client, identify_var_type_prompt_list, response_format=response_format, temperature=0.0)\n",
    "#     if response_format == 'json':\n",
    "#         identified_var_types = [extract_response_func(i) for i in identified_var_types]\n",
    "#     for (chunk_index, var_types) in enumerate(identified_var_types):\n",
    "#         chunk = all_chunks[chunk_index]\n",
    "#         chunk['var_types'] = var_types\n",
    "#     return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_type_definitions = {\n",
    "#     \"driver\": \"fundamental human causes that lead to certain impacts on the environment to meet basic human needs.\",\n",
    "#     \"pressure\": \"negative phenomena or activities affecting the environment or ecosystems, which are caused by drivers or occur naturally.\",\n",
    "#     \"state\": \"the quantity and quality of physical, chemical, and biological phenomena within a specific timeframe and area.\",\n",
    "#     \"impact\": \"adverse changes in environmental conditions, ecosystem functions, or human well-being.\",\n",
    "#     \"response\": \"any behavior, action, or effort to protect the environment, address environmental issues, or be environmentally friendly.\"\n",
    "# }\n",
    "# for variable_definition_file in glob.glob(\"contexts/variable_definitions/*.json\"):\n",
    "#     variable_definitions = json.load(open(variable_definition_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:09<00:00, 62.77it/s] \n"
     ]
    }
   ],
   "source": [
    "# prompt_variables = {\n",
    "#     \"var_types\": \"\\n\".join([f\"{var_type}: {var_type_def}\" for var_type, var_type_def in var_type_definitions.items()]),\n",
    "# }\n",
    "# prompts = json.load(open('prompts/identify_var_types.json'))\n",
    "# system_prompt_blocks = prompts['system_prompt_blocks']\n",
    "# user_prompt_blocks = prompts['user_prompt_blocks']\n",
    "# all_chunks = []\n",
    "# for chunk_file in glob.glob(\"data/v2/tmp/chunk/chunk_summaries_w_ktte/*.json\"):\n",
    "#     chunks = json.load(open(chunk_file))\n",
    "#     all_chunks += chunks\n",
    "# # identify the variables in three prompts:\n",
    "# # First, identify if there are any mentions about the var types by extracting the sentences that mention the var types\n",
    "# # all_chunks = all_chunks[:1] # test run\n",
    "# system_prompt_blocks = [prompt_block[1] for prompt_block in system_prompt_blocks]\n",
    "# user_prompt_blocks = [prompt_block[1] for prompt_block in user_prompt_blocks]\n",
    "# all_chunks = identify_var_types(all_chunks, openai_client, system_prompt_blocks, user_prompt_blocks, prompt_variables)\n",
    "\n",
    "# If so, identify the corresponding variables by assigning variables to the sentences\n",
    "# If no existing variables can be matched, assign it to 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = []\n",
    "for chunk_file in glob.glob(\"data/v2/tmp/chunk/chunk_summaries_w_ktte/*.json\"):\n",
    "    chunks = json.load(open(chunk_file))\n",
    "    all_chunks += chunks\n",
    "len(all_chunks)\n",
    "save_json(all_chunks, \"data/v2/tmp/pipeline/init/chunks.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:20<00:00, 28.84it/s]\n"
     ]
    }
   ],
   "source": [
    "var_type_definitions = json.load(open('GPTUtils/contexts/var_type_definitions.json'))\n",
    "prompts = json.load(open('GPTUtils/prompts/identify_var_types.json'))\n",
    "system_prompt_blocks = prompts['system_prompt_blocks']\n",
    "user_prompt_blocks = prompts['user_prompt_blocks']\n",
    "prompt_variables = {\n",
    "    \"var_types\": \"\\n\".join([f\"{var_type}: {var_type_def}\" for var_type, var_type_def in var_type_definitions.items()]),\n",
    "}\n",
    "all_chunks = json.load(open(\"data/v2/tmp/pipeline/init/chunks.json\"))\n",
    "print(len(all_chunks))\n",
    "# all_chunks = all_chunks[:10]\n",
    "system_prompt_blocks = [prompt_block[1] for prompt_block in system_prompt_blocks]\n",
    "user_prompt_blocks = [prompt_block[1] for prompt_block in user_prompt_blocks]\n",
    "all_chunks = query.identify_var_types(all_chunks, openai_client, system_prompt_blocks, user_prompt_blocks, prompt_variables)\n",
    "save_json(all_chunks, \"data/v2/tmp/pipeline/identify_var_types/chunk_w_var_types.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = json.load(open(\"data/v2/tmp/pipeline/identify_var_types/chunk_w_var_types.json\"))\n",
    "\n",
    "for chunk in all_chunks:\n",
    "    var_type_result = chunk['identify_var_types_result']\n",
    "    var_type_result = list(filter(lambda x: x[\"var_type\"] != 'none', var_type_result))\n",
    "    chunk['identify_var_types_result'] = var_type_result\n",
    "\n",
    "save_json(all_chunks, \"data/v2/tmp/pipeline/identify_var_types/chunk_w_var_types_filtered.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 774/774 [00:36<00:00, 20.99it/s]\n"
     ]
    }
   ],
   "source": [
    "var_type_definitions = json.load(open('GPTUtils/contexts/var_type_definitions.json'))\n",
    "var_definitions = {}\n",
    "for var_type in var_type_definitions.keys():\n",
    "    var_definitions_by_type = json.load(open(f\"GPTUtils/contexts/variable_definitions/{var_type}_variables_def.json\"))\n",
    "    var_definitions[var_type] = var_definitions_by_type\n",
    "\n",
    "prompts = json.load(open('GPTUtils/prompts/identify_vars.json'))\n",
    "system_prompt_blocks = prompts['system_prompt_blocks']\n",
    "user_prompt_blocks = prompts['user_prompt_blocks']\n",
    "prompt_variables = {}\n",
    "for var_type, var_type_def in var_type_definitions.items():\n",
    "    prompt_variables[var_type] = {\n",
    "        \"definition\": var_type_def,\n",
    "        \"vars\": \"\\n\".join([f\"{var_name}: {var_def}\" for var_name, var_def in var_definitions[var_type].items()])\n",
    "    }\n",
    "all_chunks = json.load(open(\"data/v2/tmp/pipeline/identify_var_types/chunk_w_var_types.json\"))\n",
    "# all_chunks = all_chunks[:10]\n",
    "system_prompt_blocks = [prompt_block[1] for prompt_block in system_prompt_blocks]\n",
    "user_prompt_blocks = [prompt_block[1] for prompt_block in user_prompt_blocks]\n",
    "all_chunks = query.identify_vars(all_chunks, openai_client, system_prompt_blocks, user_prompt_blocks, prompt_variables)\n",
    "save_json(all_chunks, \"data/v2/tmp/pipeline/identify_vars/chunk_w_vars.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "for var_definition_file in glob.glob(\"GPTUtils/contexts/variable_definitions/*.json\"):\n",
    "    var_definitions = json.load(open(var_definition_file))\n",
    "    var_def_list = [\n",
    "        {\n",
    "            \"var_name\": var_name,\n",
    "            \"definition\": var_def['definition'],\n",
    "            \"factor_type\": var_def['factor_type']\n",
    "        }\n",
    "        for var_name, var_def in var_definitions.items()\n",
    "    ]\n",
    "    with open(var_definition_file, 'w') as f:\n",
    "        json.dump(var_definitions_by_type, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lyudao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
